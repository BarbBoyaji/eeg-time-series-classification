{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_FCN_Combination_Model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP89NXGlRf028u69Xjv1pRr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mA-kOGi_09ba","colab_type":"code","outputId":"58dcfcc6-e275-48bf-b21e-5e87f6f94e7b","executionInfo":{"status":"ok","timestamp":1583969418739,"user_tz":420,"elapsed":1051,"user":{"displayName":"BARBARA BOYAJIAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVo3bmr6fME5kcpZGqfyaZgBGl2sB4jqv29x_G=s64","userId":"16085459876406604783"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NrKgfdzU1CD0","colab_type":"code","colab":{}},"source":["import sys\n","\n","sys.path.append('/content/gdrive/My Drive/Colab Notebooks/ECE_Project')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wj0DnzHZ1KS8","colab_type":"code","colab":{}},"source":["import CNN_Lib\n","import CNN_BuildingBlock_Lib as BB\n","import RNN_BuildingBlock_Lib as RNN_BB\n","import CombinationModel as ComboCNN\n","import CombinationModel_RNN_CNN as RNN_CNN\n","import CombinationModel_LSTM_FCN as LSTM_FCN\n","import numpy as np \n","import torch\n","from torch.autograd import Variable\n","import random\n","import pdb\n","import copy\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Tshz25P1V4t","colab_type":"code","outputId":"32132288-1fe2-4f8f-c7cb-1ee470806fbb","executionInfo":{"status":"ok","timestamp":1583969435936,"user_tz":420,"elapsed":1673,"user":{"displayName":"BARBARA BOYAJIAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVo3bmr6fME5kcpZGqfyaZgBGl2sB4jqv29x_G=s64","userId":"16085459876406604783"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["dir = '/content/gdrive/My Drive/Colab Notebooks/ECE_Project'\n","X_test = np.load(dir + '/X_test.npy')\n","y_test = np.load(dir + '/y_test.npy')\n","person_train_valid = np.load(dir + '/person_train_valid.npy')\n","X_train_valid = np.load(dir + '/X_train_valid.npy')\n","y_train_valid = np.load(dir + '/y_train_valid.npy')\n","person_test = np.load(dir + '/person_test.npy')\n","print ('Training/Valid data shape: {}' .format(X_train_valid.shape))\n","print ('Test data shape: {}' .format(X_test.shape))\n","print ('Training/Valid target shape: {}' .format(y_train_valid.shape))\n","print ('Test target shape: {}' .format(y_test.shape))\n","print ('Person train/valid shape: {}' .format(person_train_valid.shape))\n","print ('Person test shape: {}' .format(person_test.shape))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training/Valid data shape: (2115, 22, 1000)\n","Test data shape: (443, 22, 1000)\n","Training/Valid target shape: (2115,)\n","Test target shape: (443,)\n","Person train/valid shape: (2115, 1)\n","Person test shape: (443, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j28b_XSI1bS0","colab_type":"code","colab":{}},"source":["#transform data into torch-readable data types\n","#2115 number of trials from 9 people\n","#four possible classes of outputs\n","#Xtrain = Variable(torch.from_numpy(X_train_valid)).cuda()\n","#ytrain = Variable(torch.from_numpy(y_train_valid)).cuda()\n","#Xtest = Variable(torch.from_numpy(X_test)).cuda()\n","#ytest = Variable(torch.from_numpy(y_test)).cuda()\n","\n","Xtrain = torch.from_numpy(X_train_valid)\n","Ytrain = torch.from_numpy(y_train_valid)\n","Xtest = torch.from_numpy(X_test)\n","Ytest = torch.from_numpy(y_test)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2HXEsfHoGAZ","colab_type":"code","colab":{}},"source":["def map_to_class(input_labels):\n","  mask1 = (input_labels == 769)*0\n","  mask2 = (input_labels == 770)*1\n","  mask3 = (input_labels == 771)*2\n","  mask4 = (input_labels == 772)*3\n","\n","  return (mask1 + mask2 + mask3 + mask4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3fG1a761dS8","colab_type":"code","outputId":"34f0d552-1e5d-4ca7-d3d0-a6fc0abd5e1e","executionInfo":{"status":"ok","timestamp":1583973766126,"user_tz":420,"elapsed":847,"user":{"displayName":"BARBARA BOYAJIAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVo3bmr6fME5kcpZGqfyaZgBGl2sB4jqv29x_G=s64","userId":"16085459876406604783"}},"colab":{"base_uri":"https://localhost:8080/","height":547}},"source":["########## INITIALIZE RNN-CNN COMBINATION MODEL ########## \n","\n","Trials, InputDim, SeqDim = X_train_valid.shape\n","num_features = InputDim\n","Tests = y_test.shape\n","\n","\n","#-----RNN tweak here----#\n","hidden_dim = 22 #above 150 and we get low training accuracy\n","num_layers = 1 #increasing this makes training take MUCH longer, similar validation and lower training accuracy\n","nonlinearity = 'tanh'\n","initialization = 'xavierNorm'\n","\n","\n","#-----CNN tweak here----#\n","num_filters = [64, 64, 32] #64, 32, 32 up to 70% V, and 64, 64, 32 plateud at ~61-63% after Epoch 1 then increased to 67% | 72 max\n","batch_size = 30   #smaller batch sizes (less than 50) offer a regularization effect | must be less than 423 bc we are using kfold validation of 5\n","num_classes = 4\n","L2 = 0.22 #higher than 0.25 and the validation doesnt reach 70\n","cnnfilter_stride = [2, 1, 1] #big filter stride makes training to acceptable validation take longer. \n","cnnfilter_size = [10, 3, 3] #smaller filter size appears to make higher validation from the beginning. lower than 2 is pretty bad?\n","cnn_padding = [1, 1, 1]\n","use_bias = [False, True, False]\n","use_maxpool = [True, True, True] #not using it makes the model overfit\n","pool_size = [5, 3, 2]\n","pool_stride = [2, 1, 1]\n","use_batchnorm = [True, True, True]\n","eps = [1e-4, 1e-4, 1e-4]\n","momentum = [0.3, 0.8, 0.5]\n","affine = [False, False, False]\n","dropout = [0.13, 0.21, 0.1, 0.55]\n","\n","#-----OPTIM tweak here----#\n","learning_rate = 0.0001 #0 we trained faster with this vs 0.0001 \n","\n","combo_model = LSTM_FCN.CombinationModel_LSTM_FCN(InputDim, SeqDim, hidden_dim, num_layers, nonlinearity, initialization, num_filters, cnnfilter_size, cnnfilter_stride, cnn_padding, use_bias, num_classes, use_maxpool, pool_size, pool_stride, use_batchnorm, eps, momentum, affine, dropout)\n","combo_model.to('cuda:0') #--- activate the GPU\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["DONE INITIALIZING\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["CombinationModel_RNN_CNN(\n","  (RNN_Block): EEG_RNN_BuildingBlock(\n","    (RNN): RNN(22, 22, batch_first=True)\n","  )\n","  (CNN_Block1): EEG_CNN_BuildingBlock(\n","    (CNN): Conv1d(22, 64, kernel_size=(10,), stride=(2,), padding=(1,), bias=False)\n","    (RELU): ReLU()\n","    (BatchNorm): BatchNorm1d(64, eps=0.0001, momentum=0.3, affine=False, track_running_stats=True)\n","    (DropOut): Dropout(p=0.13, inplace=False)\n","    (MaxPool): MaxPool1d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (CNN_Block2): EEG_CNN_BuildingBlock(\n","    (CNN): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n","    (RELU): ReLU()\n","    (BatchNorm): BatchNorm1d(64, eps=0.0001, momentum=0.8, affine=False, track_running_stats=True)\n","    (DropOut): Dropout(p=0.21, inplace=False)\n","    (MaxPool): MaxPool1d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (CNN_Block3): EEG_CNN(\n","    (CNN): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n","    (RELU): ReLU()\n","    (BatchNorm): BatchNorm1d(32, eps=0.0001, momentum=0.5, affine=False, track_running_stats=True)\n","    (DropOut): Dropout(p=0.1, inplace=False)\n","    (MaxPool): MaxPool1d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n","    (FC1): Linear(in_features=7808, out_features=244, bias=True)\n","    (DropOutFC): Dropout(p=0.55, inplace=False)\n","    (FC2): Linear(in_features=244, out_features=4, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"q300uxJ723su","colab_type":"code","colab":{}},"source":["########## CHOOSE LOSS  ###########\n","loss = torch.nn.CrossEntropyLoss()\n","\n","######### CHOOSE OPTIMIZER ########\n","optim = torch.optim.Adam(combo_model.parameters(), lr=learning_rate, weight_decay=L2)\n","#optim = torch.optim.Adadelta(combo_model.parameters()) << does worse than Adam, we overfit so much "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTS1xtw2j3PR","colab_type":"code","outputId":"dea9170c-f9cc-4f54-834e-a21e65ea3867","executionInfo":{"status":"error","timestamp":1583861400238,"user_tz":420,"elapsed":1514380,"user":{"displayName":"BARBARA BOYAJIAN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVo3bmr6fME5kcpZGqfyaZgBGl2sB4jqv29x_G=s64","userId":"16085459876406604783"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["######## TRAIN IT ########\n","#------ With Early Stopping AND K-Fold Validation -----#\n","stop_now = False\n","loss_store = []\n","validation_store = []\n","training_store = []\n","network_store = []\n","model_store = []\n","\n","epochs = 1\n","kfolds = 15\n","iterations = 1500\n","iter_ = 0\n","validate_fold = 0\n","SEED = 2000\n","\n","#k fold validation here\n","np.random.seed(random.randint(1,SEED))\n","fold_size = int(Trials/kfolds)\n","idx = np.arange(Trials)\n","np.random.shuffle(idx)\n","Xtrain_Shuffled = Xtrain[idx]\n","Ytrain_Shuffled = Ytrain[idx]\n","\n","FoldsX = Xtrain_Shuffled.split(fold_size)\n","FoldsY = Ytrain_Shuffled.split(fold_size)\n","\n","for epoch in range(epochs):\n","  if stop_now:\n","    break\n","\n","  print(f\"...... Training for Epoch {epoch} ......\")\n","  train_correct = 0\n","  train_total = 0\n","\n","\n","  for k in range(kfolds): \n","\n","    #create training folds by excluding validate fold\n","    train_folds = list(range(kfolds))\n","    del train_folds[validate_fold]\n","    train_folds = np.array(train_folds)\n","\n","    TrainX = torch.cat([FoldsX[f] for f in train_folds]) \n","    TrainY = torch.cat([FoldsY[f] for f in train_folds])\n","    #create validate fold\n","    ValidateX = FoldsX[validate_fold]\n","    ValidateY = FoldsY[validate_fold]\n","\n","    #initialize the network within the kfold loop\n","    combo_model = RNN_CNN.CombinationModel_RNN_CNN(InputDim, SeqDim, hidden_dim, num_layers, \n","                                                   nonlinearity, initialization, num_filters, \n","                                                   cnnfilter_size, cnnfilter_stride, cnn_padding, \n","                                                   use_bias, num_classes, use_maxpool, pool_size, \n","                                                   pool_stride, use_batchnorm, eps, momentum, affine, dropout)\n","    combo_model.to('cuda:0') #--- activate the GPU\n","    optim = torch.optim.Adam(combo_model.parameters(), lr=learning_rate, weight_decay=L2) \n","    \n","\n","    print(f\"______ Training for k-folds {train_folds} ______\")\n","    for i in range(iterations):\n","      #do the batches\n","      idx = np.arange(TrainX.size(0))\n","      np.random.shuffle(idx)\n","      idx = idx[0:batch_size]\n","\n","      #process the input data\n","      xtrain = TrainX[idx].view(batch_size, SeqDim, InputDim)\n","      xtrain = xtrain.to('cuda:0').requires_grad_()\n","      ytrain = TrainY[idx]\n","\n","      #put the model in training mode\n","      combo_model.train(True)\n","\n","      #forward pass\n","      optim.zero_grad()\n","      outFC = combo_model.forward(xtrain.float())\n","  \n","      #map to classes\n","      classes = map_to_class(ytrain.long())\n","      classes = classes.to('cuda:0')\n","\n","      #backward pass (gradient calculation)\n","      probs = loss(outFC, classes)\n","      probs.backward()\n","\n","      #update weights\n","      optim.step()\n","\n","      #update iter counter\n","      iter_+=1\n","\n","      #calculate training accuracy\n","      values, train_pred = torch.max(outFC, 1)\n","      train_correct += (1*(train_pred == classes)).sum()\n","      train_total += float(classes.size(0))\n","\n","    print(f\"______ Validating for k-fold {k} ______\")\n","    combo_model.eval()\n","    \n","    total = 0\n","    correct = 0\n","\n","    #process the input data\n","    idx = np.random.randint(0, Tests, size=batch_size)\n","    xvalid = ValidateX.view(-1, SeqDim, InputDim)\n","    xvalid = xvalid.to('cuda:0')\n","    yvalid = ValidateY\n","\n","    #forward prop\n","    predict = combo_model(xvalid.float())\n","    \n","    #predict\n","    values, predicted_classes = torch.max(predict, 1)\n","    expected_classes = map_to_class(yvalid)        \n","    correct += (1*(predicted_classes == expected_classes.to('cuda:0'))).sum()\n","    total +=float(predicted_classes.size(0))\n","    \n","    #evaluate\n","    validation_accuracy = 100*(correct/total)\n","    training_accuracy = 100*(train_correct/train_total)\n","\n","    print(f\"correct: {correct}, total: {total}\")\n","    #print(f\"prediction: {predicted_classes}\\nexpected_classes: {expected_classes}\")\n","    print(f\"Iteration: {iter_}, Loss: {probs.item()}, Validation Accuracy: {validation_accuracy}%, Training Accuracy: {training_accuracy}%\\n\")  \n","\n","    #store info for graphing later\n","    validation_store.append(validation_accuracy)\n","    loss_store.append(probs)\n","    training_store.append(training_accuracy)\n","\n","    #store the model\n","    model_store.append(copy.deepcopy(combo_model))\n","\n","    #iterate the validate fold\n","    validate_fold +=1\n","    \n","    #--- Early stopping criterion here --- #\n","    if validation_accuracy > 73.0:\n","      #store\n","      print(\"Early Stopping!\")\n","      stop_now = True\n","      break\n","    \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["...... Training for Epoch 0 ......\n","DONE INITIALIZING\n","______ Training for k-folds [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] ______\n","______ Validating for k-fold 0 ______\n","correct: 41, total: 141.0\n","Iteration: 1500, Loss: 0.3712298572063446, Validation Accuracy: 29.078012466430664%, Training Accuracy: 77.33111572265625%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14] ______\n","______ Validating for k-fold 1 ______\n","correct: 51, total: 141.0\n","Iteration: 3000, Loss: 0.29168206453323364, Validation Accuracy: 36.17021179199219%, Training Accuracy: 77.2477798461914%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14] ______\n","______ Validating for k-fold 2 ______\n","correct: 36, total: 141.0\n","Iteration: 4500, Loss: 0.28391727805137634, Validation Accuracy: 25.53191566467285%, Training Accuracy: 77.36000061035156%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14] ______\n","______ Validating for k-fold 3 ______\n","correct: 44, total: 141.0\n","Iteration: 6000, Loss: 0.3882535696029663, Validation Accuracy: 31.205671310424805%, Training Accuracy: 77.40111541748047%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14] ______\n","______ Validating for k-fold 4 ______\n","correct: 46, total: 141.0\n","Iteration: 7500, Loss: 0.3644004166126251, Validation Accuracy: 32.624114990234375%, Training Accuracy: 77.3564453125%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14] ______\n","______ Validating for k-fold 5 ______\n","correct: 46, total: 141.0\n","Iteration: 9000, Loss: 0.24807380139827728, Validation Accuracy: 32.624114990234375%, Training Accuracy: 77.46259307861328%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14] ______\n","______ Validating for k-fold 6 ______\n","correct: 50, total: 141.0\n","Iteration: 10500, Loss: 0.3624471127986908, Validation Accuracy: 35.46099090576172%, Training Accuracy: 77.6031723022461%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14] ______\n","______ Validating for k-fold 7 ______\n","correct: 38, total: 141.0\n","Iteration: 12000, Loss: 0.38061627745628357, Validation Accuracy: 26.950353622436523%, Training Accuracy: 77.55471801757812%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14] ______\n","______ Validating for k-fold 8 ______\n","correct: 45, total: 141.0\n","Iteration: 13500, Loss: 0.28234976530075073, Validation Accuracy: 31.914892196655273%, Training Accuracy: 77.68345642089844%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14] ______\n","______ Validating for k-fold 9 ______\n","correct: 53, total: 141.0\n","Iteration: 15000, Loss: 0.3835045099258423, Validation Accuracy: 37.58864974975586%, Training Accuracy: 77.59733581542969%\n","\n","DONE INITIALIZING\n","______ Training for k-folds [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14] ______\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZzJl-fEZdXsC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}